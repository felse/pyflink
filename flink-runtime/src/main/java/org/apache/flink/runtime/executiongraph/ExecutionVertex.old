/*
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package org.apache.flink.runtime.executiongraph;

import static org.apache.flink.runtime.execution.ExecutionState.CANCELED;
import static org.apache.flink.runtime.execution.ExecutionState.FAILED;
import static org.apache.flink.runtime.execution.ExecutionState.FINISHED;

import java.util.ArrayList;
import java.util.HashSet;
import java.util.List;
import java.util.concurrent.CopyOnWriteArrayList;

import org.apache.flink.runtime.blob.BlobKey;
import org.slf4j.Logger;
import org.apache.flink.runtime.JobException;
import org.apache.flink.runtime.deployment.GateDeploymentDescriptor;
import org.apache.flink.runtime.deployment.TaskDeploymentDescriptor;
import org.apache.flink.runtime.execution.ExecutionState;
import org.apache.flink.runtime.instance.AllocatedSlot;
import org.apache.flink.runtime.instance.Instance;
import org.apache.flink.runtime.jobgraph.DistributionPattern;
import org.apache.flink.runtime.jobgraph.JobEdge;
import org.apache.flink.runtime.jobgraph.JobID;
import org.apache.flink.runtime.jobgraph.JobVertexID;
import org.apache.flink.runtime.jobmanager.scheduler.CoLocationConstraint;
import org.apache.flink.runtime.jobmanager.scheduler.CoLocationGroup;
import org.apache.flink.runtime.jobmanager.scheduler.Scheduler;
import org.apache.flink.runtime.jobmanager.scheduler.NoResourceAvailableException;

/**
 * The ExecutionVertex is a parallel subtask of the execution. It may be executed once, or several times, each of
 * which time it spawns an {@link Execution}.
 */
public class ExecutionVertex {

	@SuppressWarnings("unused")
	private static final Logger LOG = ExecutionGraph.LOG;
	
	private static final int MAX_DISTINCT_LOCATIONS_TO_CONSIDER = 8;
	
	// --------------------------------------------------------------------------------------------
	
	private final ExecutionJobVertex jobVertex;
	
	private final IntermediateResultPartition[] resultPartitions;
	
	private final ExecutionEdge[][] inputEdges;
	
	private final int subTaskIndex;
	
	private final List<Execution> priorExecutions;
	
	private volatile CoLocationConstraint locationConstraint;
	
	private volatile Execution currentExecution;	// this field must never be null
	
	// --------------------------------------------------------------------------------------------

	/**
	 * The ID of the vertex.
	 */
	private final ExecutionVertexID vertexID;

	/**
	 * The group vertex this vertex belongs to.
	 */
	private final ExecutionGroupVertex groupVertex;

	/**
	 * The execution graph is vertex belongs to.
	 */
	private final ExecutionGraph executionGraph;

	/**
	 * The allocated resources assigned to this vertex.
	 */
	private final AtomicReference<AllocatedResource> allocatedResource = new AtomicReference<AllocatedResource>(null);

	/**
	 * The allocation ID identifying the allocated resources used by this vertex
	 * within the instance.
	 */
	private volatile AllocationID allocationID = null;

	/**
	 * A list of {@link VertexAssignmentListener} objects to be notified about changes in the instance assignment.
	 */
	private final CopyOnWriteArrayList<VertexAssignmentListener> vertexAssignmentListeners = new CopyOnWriteArrayList<VertexAssignmentListener>();

	private final CopyOnWriteArrayList<ActorRef> vertexAssignmentListenerActors = new
			CopyOnWriteArrayList<ActorRef>();

	/**
	 * A map of {@link ExecutionListener} objects to be notified about the state changes of a vertex.
	 */
	private final ConcurrentMap<Integer, ExecutionListener> executionListeners = new ConcurrentSkipListMap<Integer, ExecutionListener>();

	private final CopyOnWriteArrayList<ActorRef> executionListenerActors = new CopyOnWriteArrayList<ActorRef>();

	/**
	 * The current execution state of the task represented by this vertex
	 */
	private final AtomicEnum<ExecutionState> executionState = new AtomicEnum<ExecutionState>(ExecutionState.CREATED);

	/**
	 * The output gates attached to this vertex.
	 */
	private final ExecutionGate[] outputGates;

	/**
	 * The input gates attached to his vertex.
	 */
	private final ExecutionGate[] inputGates;

	/**
	 * The index of this vertex in the vertex group.
	 */
	private volatile int indexInVertexGroup = 0;

	/**
	 * Stores the number of times the vertex may be still be started before the corresponding task is considered to be
	 * failed.
	 */
	private final AtomicInteger retriesLeft;


	/**
	 * The execution pipeline this vertex is part of.
	 */
	private final AtomicReference<ExecutionPipeline> executionPipeline = new AtomicReference<ExecutionPipeline>(null);

	/**
	 * Flag to indicate whether the vertex has been requested to cancel while in state STARTING
	 */
	private final AtomicBoolean cancelRequested = new AtomicBoolean(false);

	/**
	 * Create a new execution vertex and instantiates its environment.
	 * 
	 * @param executionGraph
	 *        the execution graph the new vertex belongs to
	 * @param groupVertex
	 *        the group vertex the new vertex belongs to
	 * @param numberOfOutputGates
	 *        the number of output gates attached to this vertex
	 * @param numberOfInputGates
	 *        the number of input gates attached to this vertex
	 */
	public ExecutionVertex(final ExecutionGraph executionGraph, final ExecutionGroupVertex groupVertex,
			final int numberOfOutputGates, final int numberOfInputGates) {
		this(new ExecutionVertexID(), executionGraph, groupVertex, numberOfOutputGates, numberOfInputGates);

		this.groupVertex.addInitialSubtask(this);
	}
	
	public ExecutionVertex(ExecutionJobVertex jobVertex, int subTaskIndex, IntermediateResult[] producedDataSets, long createTimestamp) {
		this.jobVertex = jobVertex;
		this.subTaskIndex = subTaskIndex;
		
		this.resultPartitions = new IntermediateResultPartition[producedDataSets.length];
		for (int i = 0; i < producedDataSets.length; i++) {
			IntermediateResultPartition irp = new IntermediateResultPartition(producedDataSets[i], this, subTaskIndex);
			this.resultPartitions[i] = irp;
			producedDataSets[i].setPartition(subTaskIndex, irp);
		}
		
		this.inputEdges = new ExecutionEdge[jobVertex.getJobVertex().getInputs().size()][];
		this.priorExecutions = new CopyOnWriteArrayList<Execution>();
		
		this.currentExecution = new Execution(this, 0, createTimestamp);
		
		// create a co-location scheduling hint, if necessary
		CoLocationGroup clg = jobVertex.getCoLocationGroup();
		if (clg != null) {
			this.locationConstraint = clg.getLocationConstraint(subTaskIndex);
		} else {
			this.locationConstraint = null;
		}
	}
	
	
	// --------------------------------------------------------------------------------------------
	//  Properties
	// --------------------------------------------------------------------------------------------
	
	public JobID getJobId() {
		return this.jobVertex.getJobId();
	}
	
	public ExecutionJobVertex getJobVertex() {
		return jobVertex;
	}
	
	public JobVertexID getJobvertexId() {
		return this.jobVertex.getJobVertexId();
	}
	
	public String getTaskName() {
		return this.jobVertex.getJobVertex().getName();
	}

	/**
	 * Inserts the input gate at the given position.
	 * 
	 * @param pos
	 *        the position to insert the input gate
	 * @param inputGate
	 *        the input gate to be inserted
	 */
	void insertInputGate(final int pos, final ExecutionGate inputGate) {

		if (this.inputGates[pos] != null) {
			throw new IllegalStateException("Input gate at position " + pos + " is not null");
		}
		return inputEdges[input];
	}
	
	public CoLocationConstraint getLocationConstraint() {
		return locationConstraint;
	}
	
	public Execution getCurrentExecutionAttempt() {
		return currentExecution;
	}
	
	public ExecutionState getExecutionState() {
		return currentExecution.getState();
	}
	
	public long getStateTimestamp(ExecutionState state) {
		return currentExecution.getStateTimestamp(state);
	}
	
	public Throwable getFailureCause() {
		return currentExecution.getFailureCause();
	}
	
	public AllocatedSlot getCurrentAssignedResource() {
		return currentExecution.getAssignedResource();
	}

	/**
	 * Updates the vertex's current execution state.
	 * 
	 * @param newExecutionState
	 *        the new execution state
	 * @param optionalMessage
	 *        an optional message related to the state change
	 */
	public ExecutionState updateExecutionState(ExecutionState newExecutionState, final String optionalMessage) {

		if (newExecutionState == null) {
			throw new IllegalArgumentException("Argument newExecutionState must not be null");
		}

		final ExecutionState currentExecutionState = this.executionState.get();
		if (currentExecutionState == ExecutionState.CANCELING) {

			// If we are in CANCELING, ignore state changes to FINISHING
			if (newExecutionState == ExecutionState.FINISHING) {
				return currentExecutionState;
			}

			// Rewrite FINISHED to CANCELED if the task has been marked to be canceled
			if (newExecutionState == ExecutionState.FINISHED) {
				LOG.info("Received transition from CANCELING to FINISHED for vertex " + toString()
					+ ", converting it to CANCELED");
				newExecutionState = ExecutionState.CANCELED;
			}
		}

		// Check and save the new execution state
		final ExecutionState previousState = this.executionState.getAndSet(newExecutionState);
		if (previousState == newExecutionState) {
			return previousState;
		}

		// Check the transition
		ExecutionStateTransition.checkTransition(true, toString(), previousState, newExecutionState);

		// Notify the listener objects
		final Iterator<ExecutionListener> it = this.executionListeners.values().iterator();
		while (it.hasNext()) {
			it.next().executionStateChanged(this.executionGraph.getJobID(), this.vertexID, newExecutionState,
				optionalMessage);
		}

		for(ActorRef actor: executionListenerActors){
			actor.tell(new ExecutionGraphMessages.ExecutionStateChanged(this.executionGraph.getJobID(),
					this.vertexID, newExecutionState, optionalMessage), ActorRef.noSender());
		}

		// The vertex was requested to be canceled by another thread
		checkCancelRequestedFlag();

		return previousState;
	}
	
	// --------------------------------------------------------------------------------------------
	//  Graph building
	// --------------------------------------------------------------------------------------------
	
	public void connectSource(int inputNumber, IntermediateResult source, JobEdge edge, int consumerNumber) {
		
		final DistributionPattern pattern = edge.getDistributionPattern();
		final IntermediateResultPartition[] sourcePartitions = source.getPartitions();
		
		ExecutionEdge[] edges = null;
		
		switch (pattern) {
			case POINTWISE:
				edges = connectPointwise(sourcePartitions, inputNumber);
				break;
				
			case BIPARTITE: 
				edges = connectAllToAll(sourcePartitions, inputNumber);
				break;
				
			default:
				throw new RuntimeException("Unrecognized distribution pattern.");
		
		}
		
		this.inputEdges[inputNumber] = edges;
		
		ExecutionGraph graph = getExecutionGraph();
		
		// add the consumers to the source
		// for now (until the receiver initiated handshake is in place), we need to register the 
		// edges as the execution graph
		for (ExecutionEdge ee : edges) {
			ee.getSource().addConsumer(ee, consumerNumber);
			graph.registerExecutionEdge(ee);
		}

		// Check the transition
		ExecutionStateTransition.checkTransition(true, toString(), expected, update);

		// Notify the listener objects
		final Iterator<ExecutionListener> it = this.executionListeners.values().iterator();
		while (it.hasNext()) {
			it.next().executionStateChanged(this.executionGraph.getJobID(), this.vertexID, update,
				null);
		}

		for(ActorRef actor: executionListenerActors){
			actor.tell(new ExecutionGraphMessages.ExecutionStateChanged(this.executionGraph.getJobID(),
							this.vertexID, update, null), ActorRef.noSender());
		}

		// Check if the vertex was requested to be canceled by another thread
		checkCancelRequestedFlag();

		return true;
	}
	
	private ExecutionEdge[] connectAllToAll(IntermediateResultPartition[] sourcePartitions, int inputNumber) {
		ExecutionEdge[] edges = new ExecutionEdge[sourcePartitions.length];
		
		for (int i = 0; i < sourcePartitions.length; i++) {
			IntermediateResultPartition irp = sourcePartitions[i];
			edges[i] = new ExecutionEdge(irp, this, inputNumber);
		}
		
		return edges;
	}

	/**
	 * Assigns the execution vertex with an {@link org.apache.flink.runtime.instance.AllocatedResource}.
	 * 
	 * @param allocatedResource
	 *        the resources which are supposed to be allocated to this vertex
	 */
	public void setAllocatedResource(final AllocatedResource allocatedResource) {

		if (allocatedResource == null) {
			throw new IllegalArgumentException("Argument allocatedResource must not be null");
		}
		else if (numSources < parallelism) {
			
			int sourcePartition;
			
			// check if the pattern is regular or irregular
			// we use int arithmetics for regular, and floating point with rounding for irregular
			if (parallelism % numSources == 0) {
				// same number of targets per source
				int factor = parallelism / numSources;
				sourcePartition = subTaskIndex / factor;
			}
			else {
				// different number of targets per source
				float factor = ((float) parallelism) / numSources;
				sourcePartition = (int) (subTaskIndex / factor);
			}
			
			return new ExecutionEdge[] { new ExecutionEdge(sourcePartitions[sourcePartition], this, inputNumber) };
		}
		else {
			if (numSources % parallelism == 0) {
				// same number of targets per source
				int factor = numSources / parallelism;
				int startIndex = subTaskIndex * factor;
				
				ExecutionEdge[] edges = new ExecutionEdge[factor];
				for (int i = 0; i < factor; i++) {
					edges[i] = new ExecutionEdge(sourcePartitions[startIndex + i], this, inputNumber);
				}
				return edges;
			}
			else {
				float factor = ((float) numSources) / parallelism;
				
				int start = (int) (subTaskIndex * factor);
				int end = (subTaskIndex == getTotalNumberOfParallelSubtasks() - 1) ?
						sourcePartitions.length : 
						(int) ((subTaskIndex + 1) * factor);
				
				ExecutionEdge[] edges = new ExecutionEdge[end - start];
				for (int i = 0; i < edges.length; i++) {
					edges[i] = new ExecutionEdge(sourcePartitions[start + i], this, inputNumber);
				}
				
				return edges;
			}
		}

		for(ActorRef actor: vertexAssignmentListenerActors){
			actor.tell(new ExecutionGraphMessages.VertexAssignmentChanged(this.getExecutionGraph().getJobID(),vertexID,
					allocatedResource), ActorRef.noSender());
		}
	}

	/**
	 * Gets the location preferences of this task, determined by the locations of the predecessors from which
	 * it receives input data.
	 * If there are more than MAX_DISTINCT_LOCATIONS_TO_CONSIDER different locations of source data, this
	 * method returns {@code null} to indicate no location preference.
	 * 
	 * @return The preferred locations for this vertex execution, or null, if there is no preference.
	 */
	public Iterable<Instance> getPreferredLocations() {
		HashSet<Instance> locations = new HashSet<Instance>();
		
		for (int i = 0; i < inputEdges.length; i++) {
			ExecutionEdge[] sources = inputEdges[i];
			if (sources != null) {
				for (int k = 0; k < sources.length; k++) {
					AllocatedSlot sourceSlot = sources[k].getSource().getProducer().getCurrentAssignedResource();
					if (sourceSlot != null) {
						locations.add(sourceSlot.getInstance());
						if (locations.size() > MAX_DISTINCT_LOCATIONS_TO_CONSIDER) {
							return null;
						}
					}
				}
			}
		}
		return locations;
	}
	
	// --------------------------------------------------------------------------------------------
	//   Actions
	// --------------------------------------------------------------------------------------------
	
	public void resetForNewExecution() {
		synchronized (priorExecutions) {
			Execution execution = currentExecution;
			ExecutionState state = execution.getState();
			
			if (state == FINISHED || state == CANCELED || state == FAILED) {
				priorExecutions.add(execution);
				currentExecution = new Execution(this, execution.getAttemptNumber()+1, System.currentTimeMillis());
				
				CoLocationGroup grp = jobVertex.getCoLocationGroup();
				if (grp != null) {
					this.locationConstraint = grp.getLocationConstraint(subTaskIndex);
				}
				
				// temp: assign new channel IDs.
				ExecutionGraph graph = getExecutionGraph();
				
				for (ExecutionEdge[] input : this.inputEdges) {
					for (ExecutionEdge e : input) {
						e.assignNewChannelIDs();
						graph.registerExecutionEdge(e);
					}
				}
			}
			else {
				throw new IllegalStateException("Cannot reset a vertex that is in state " + state);
			}
		}
	}
	
	public void scheduleForExecution(Scheduler scheduler, boolean queued) throws NoResourceAvailableException {
		this.currentExecution.scheduleForExecution(scheduler, queued);
	}
	
	public void deployToSlot(AllocatedSlot slot) throws JobException {
		this.currentExecution.deployToSlot(slot);
	}
	
	public void cancel() {
		this.currentExecution.cancel();
	}
	
	public void fail(Throwable t) {
		this.currentExecution.fail(t);
	}
	
	// --------------------------------------------------------------------------------------------
	//   Notifications from the Execution Attempt
	// --------------------------------------------------------------------------------------------
	
	void executionFinished() {
		jobVertex.vertexFinished(subTaskIndex);
	}
	
	void executionCanceled() {
		jobVertex.vertexCancelled(subTaskIndex);
	}
	
	void executionFailed(Throwable t) {
		jobVertex.vertexFailed(subTaskIndex, t);
	}
	
	// --------------------------------------------------------------------------------------------
	//   Miscellaneous
	// --------------------------------------------------------------------------------------------
	
	/**
	 * Simply forward this notification. This is for logs and event archivers.
	 * 
	 * @param executionId
	 * @param newState
	 * @param error
	 */
	void notifyStateTransition(ExecutionAttemptID executionId, ExecutionState newState, Throwable error) {
		getExecutionGraph().notifyExecutionChange(getJobvertexId(), subTaskIndex, executionId, newState, error);
	}

	/**
	 * Registers the {@link VertexAssignmentListener} object for this vertex. This object
	 * will be notified about reassignments of this vertex to another instance.
	 * 
	 * @param vertexAssignmentListener
	 *        the object to be notified about reassignments of this vertex to another instance
	 */
	public void registerVertexAssignmentListener(final VertexAssignmentListener vertexAssignmentListener) {

		this.vertexAssignmentListeners.addIfAbsent(vertexAssignmentListener);
	}

	public void registerVertexAssignmentListener(final ActorRef vertexAssignmentListener){
		this.vertexAssignmentListenerActors.addIfAbsent(vertexAssignmentListener);
	}

	/**
	 * Unregisters the {@link VertexAssignmentListener} object for this vertex. This object
	 * will no longer be notified about reassignments of this vertex to another instance.
	 * 
	 * @param vertexAssignmentListener
	 *        the listener to be unregistered
	 */
	public void unregisterVertexAssignmentListener(final VertexAssignmentListener vertexAssignmentListener) {

		this.vertexAssignmentListeners.remove(vertexAssignmentListener);
	}


	/**
	 * Registers the {@link ExecutionListener} object for this vertex. This object
	 * will be notified about particular events during the vertex's lifetime.
	 * 
	 * @param executionListener
	 *        the object to be notified about particular events during the vertex's lifetime
	 */
	public void registerExecutionListener(final ExecutionListener executionListener) {

		final Integer priority = Integer.valueOf(executionListener.getPriority());

		if (priority.intValue() < 0) {
			LOG.error("Priority for execution listener " + executionListener.getClass() + " must be non-negative.");
			return;
		}
		
		// create the output gate deployment descriptors
		List<GateDeploymentDescriptor> outputGates = new ArrayList<GateDeploymentDescriptor>(resultPartitions.length);
		for (IntermediateResultPartition partition : resultPartitions) {
			for (List<ExecutionEdge> channels : partition.getConsumers()) {
				outputGates.add(GateDeploymentDescriptor.fromEdges(channels));
			}
		}
		
		List<BlobKey> jarFiles = getExecutionGraph().getRequiredJarFiles();
		
		return new TaskDeploymentDescriptor(getJobId(), getJobvertexId(), executionId, getTaskName(), 
				subTaskIndex, getTotalNumberOfParallelSubtasks(), 
				getExecutionGraph().getJobConfiguration(), jobVertex.getJobVertex().getConfiguration(),
				jobVertex.getJobVertex().getInvokableClassName(), outputGates, inputGates, jarFiles, slot.getSlotNumber());
	}

	public void registerExecutionListener(final ActorRef executionListener){
		this.executionListenerActors.addIfAbsent(executionListener);
	}

	/**
	 * Unregisters the {@link ExecutionListener} object for this vertex. This object
	 * will no longer be notified about particular events during the vertex's lifetime.
	 * 
	 * @param executionListener
	 *        the object to be unregistered
	 */
	public void unregisterExecutionListener(final ExecutionListener executionListener) {

		this.executionListeners.remove(Integer.valueOf(executionListener.getPriority()));
	}
	
	/**
	 * Creates a simple name representation in the style 'taskname (x/y)', where
	 * 'taskname' is the name as returned by {@link #getTaskName()}, 'x' is the parallel
	 * subtask index as returned by {@link #getParallelSubtaskIndex()}{@code + 1}, and 'y' is the total
	 * number of tasks, as returned by {@link #getTotalNumberOfParallelSubtasks()}.
	 * 
	 * @return A simple name representation.
	 */
	public String getSimpleName() {
		return getTaskName() + " (" + (getParallelSubtaskIndex()+1) + '/' + getTotalNumberOfParallelSubtasks() + ')';
	}
	
	@Override
	public String toString() {
		return getSimpleName();
	}
}
